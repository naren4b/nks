| #  | Why Kafka (Problem)                        | When to Use It                                                            | How to Apply It                                      | What Kafka Concept Solves It   | Example Scenario                                            |
| -- | -------------------------------------------| ------------------------------------------------------------------------- | ---------------------------------------------------- | -------------------------------| ----------------------------------------------------------- |
| 1  | Need to handle billions of events at scale | When your system ingests continuous, massive streams                      | Scale horizontally with partitions                   | Topics + Partitions            | LinkedIn handling profile views, job clicks, ad impressions |
| 2  | Multiple teams need the same data          | When analytics, fraud detection, and reporting all need identical streams | Use independent consumer groups                      | Consumer Groups                | Payment service → Fraud team + Analytics + Data Warehouse   |
| 3  | Debugging & ML need data replay            | When you need to reprocess past data                                      | Enable log retention & control offsets               | Offsets + Retention            | Replaying 1 year of user clicks to re-train an ML model     |
| 4  | Must support both real-time + batch        | When you want one pipeline for dashboards + ETL                           | Mix stream consumers & batch consumers (via Connect) | Kafka Connect + Stream APIs    | E-commerce system: live inventory + nightly sales reports   |
| 5  | Prevent data loss on failures              | When uptime and durability are mission-critical                           | Replicate partitions across brokers                  | Replication + Leader/Follower  | Bank processing transactions with 0 tolerance for loss      |
| 6  | Avoid producer-consumer coupling           | When new consumers must join without disturbing producers                 | Producers write once, consumers subscribe freely     | Decoupled Pub/Sub              | IoT sensor data → analytics, monitoring, ML pipelines       |
| 7  | Need event ordering                        | When events per user/session must stay in order                           | Key-based partitioning                               | Partition + Ordering Guarantee | Chat app → messages for same user land in order             |
| 8  | Process streams in motion                  | When you must enrich/filter/aggregate data on the fly                     | Use Kafka Streams or KSQL                            | Stream Processing              | Ride-sharing: calculate ETA with live traffic data          |
| 9  | Integrate with existing systems            | When data must flow to DBs, cloud storage, or other clusters              | Use Kafka Connect connectors                         | Connectors                     | Push logs to Elastic, load sales into Snowflake             |
| 10 | Build geo-distributed systems              | When you need multi-DC/cloud active-active setups                         | Replicate topics across clusters                     | MirrorMaker / Cluster Linking  | Global SaaS syncing events across regions                   |
